\documentclass[12pt]{article}
\usepackage{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{appendix}
\usepackage{multicol}
\usepackage{stmaryrd}
\usepackage{algorithm, algorithmic}

\theoremstyle{plain}
\newtheorem{thm}{Théorème}[section]
\newtheorem{lemme}[thm]{Lemme}
\newtheorem{remarque}[thm]{Remarque}
\newtheorem{defi}[thm]{Définition}
\newtheorem{propo}[thm]{Proposition}
\newtheorem{nota}[thm]{Notation}

\renewcommand{\a}{\alpha}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} 
\newcommand{\F}{\mathbb{F}} 
\newcommand{\A}{\mathcal{A}} 
\newcommand{\e}{\mathbf{e}}  
\newcommand{\s}{\mathbf{s}} 
\newcommand{\K}{\mathbb{K}} 
\newcommand{\J}{\mathcal{J}} 
\newcommand{\D}{\mathcal{D}} 

% traduction des mots pour les algos
\floatname{algorithm}{Algorithme}
\renewcommand{\algorithmicrequire}{\textbf{Entrées:}}
\renewcommand{\algorithmicensure}{\textbf{Sortie:}}
\renewcommand{\algorithmicrepeat}{\textbf{Faire}}
\renewcommand{\algorithmicuntil}{\textbf{Tant que}}
\renewcommand{\algorithmicreturn}{\textbf{Retourne}}

\title{Projet - Wave}
\author{Lansade Suzanne}
\author{Palandjian Eva}

\begin{document}

\begin{titlepage}

\center

\textsc{\LARGE Université de Bordeaux}\\[2.0cm]
\textsc{\Large Master 2 : Cryptologie et Sécurité Informatique}\\[0.5cm] 
\textsc{\large Projet de fin d'études}\\[1.2cm] 

\HRule \\[0.4cm]
{ \huge \bfseries Wave - Un procédé de signature \\ à base de codes correcteurs}\\[0.3cm] 
\HRule \\[1.3cm]


\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
Suzanne \textsc{Lansade}\\
Eva \textsc{Palandjian}\\
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Encadrant:} \\
Gilles \textsc{Zemor}
\end{flushright}
\end{minipage}\\[2cm]

\begin{large}
Février, 2020
\end{large}

\vspace{0.5in}

\includegraphics [scale=0.2]{include/Universite_Bordeaux.jpg}

\end{titlepage}

\newpage
\tableofcontents
\newpage

\section*{Introduction}
\addcontentsline{toc}{section}{\protect\numberline{}Introduction}

- Passage au post-quantique --> On cherche des alternatives à RSA et DH.\\
- Appel d'offre NIST \\
- On aimerai bien un système de signature utilisant les codes, puisque le problème du décodage d'un code aléatoire est NP-complet. \\
- Ça marche pas mal pour le chiffrement, mais encore très compliqué pour les signatures, comme en témoigne le tableau des soumissions au NIST pour le second tour. \\

\begin{figure}[h]
\label{nist 2}
\begin{center}
\includegraphics [scale=0.4]{include/nist_second_tour.png}
\end{center}
\caption{\small Comparaison des soumissions au NIST du second tour.}
\end{figure}
\noindent Alors pourquoi est-il si compliqué de faire des signatures avec des codes correcteurs ? \\
- car il est difficile de tomber dans l'ensemble des syndromes facilement décodables, ie. difficile de créer une fonction de hachage qui envoie le message $m$ dans l'ensemble des syndromes possibles. En effet, pour un décodage au sens stricte il faudrait un syndrome $s$ associé à un unique mot $c$ du code, le plus proche de $m$.\\
quand on chiffre -> ne pose pas de problème. \\
quand on signe -> pose un problème car il est dur de trouver un syndrome de cette sorte. \\
Les solutions à ce problème ont pour l'instant soit été cassées, soit impraticables.\\
La solution de Wave est d'enlever la restriction au mot le plus proche. On cherche maintenant une famille de codes permettant de trouver, pour un mot quelconque, un des mots de code à distance $\omega$. En particulier, la distance de décodage $\omega$ est très grande, ce qui assure typiquement de l’existence d’un mot de code à distance $\omega$.\\
Explication rapide du schéma wave + on cherchera à rendre les sorties uniformes + preuves de sécurité. \\

\section{Le schéma de signature Wave}
Nous allons détailler dans cette section le schéma de signature Wave. C'est un schéma de type hache et signe à base de codes correcteurs. Pour des raisons de clarté nous oublierons dans un premier temps la problématique du hachage. Nous la réintroduirons en fin de rapport afin de proposer une preuve formelle de la sécurité du schéma, où la fonction de hachage est alors nécessaire. Pour l'instant, nous considérerons que l'entrée de l'algorithme de signature est déjà un syndrome du code considéré.\\
Le schéma de signature Wave s'appuie sur une famille de codes appelés des codes $(U,U+V)$-généralisés. La structure de ces codes nous permettra de proposer un algorithme de décodage $\mathcal{D}$ utilisant une trappe $T$ et donnant un avantage par rapport à un algorithme de décodage générique. Ce système s'appuie aussi sur la notion de fonctions GPV en moyenne, que nous détaillerons.

\subsection{La famille de codes (U,U+V)-généralisés}
Pour définir la famille de code utilisée dans le schéma de signature Wave, on part de deux codes de longueur $n/2$ aléatoires de dimensions respectives $k_u$ et $k_v$. On a premièrement la définition suivante :

\begin{defi}\label{UV} (Code (U,U+V).) Un code $(U,U+V)$ est un code de longueur $n$ et de dimension $k=k_U+k_V$ et tel que :
\begin{center}
$(U,U+V) = \{(u,u+v)$ tel que $u \in U$ et $v \in V \}$
\end{center}
\end{defi}


En revanche, pour le système de signature Wave, nous n'utiliserons pas cette définition. En effet, on peut facilement tirer des informations sur la structure de ces codes.\\


\begin{defi}($hull$).
Le  $hull$ d'un code $\mathcal{C}$ est défini comme $hull(\mathcal{C}) := \mathcal{C} \cap \mathcal{C}^{\bot}$
\end{defi}

\begin{propo}\label{dim_hull}
Soit $\mathcal{C}$ un code aléatoire binaire de longueur $n$ et de dimension $k$, alors on s'attend à avoir $dim(hull(\mathcal{C}))\sim\mathcal{O}(1)$. De plus : $$ \mathbb{P}\big(dim(hull(\mathcal{C})\big) \leq t) \ \geq\ 1 - \mathcal{O}(2^{-t}) $$
\end{propo}

\begin{propo}\label{dim_hull_UV}
Soit $UV$ un code $(U,U+V)$ binaire permuté de longueur $n$ tel que $k_U > k_V$, alors nous avons avec probabilité $1-\mathcal{O}(2^{k_U-k_V})$
$$ dim(hull(UV)) = k_U - k_V $$
\end{propo}

\begin{proof}[Preuve]
En annexe.
\end{proof}

Ainsi nous ne pouvons pas utiliser les codes $(U,U+V)$ binaires où $\dim(U) > \dim(V)$ puisque nous pouvons facilement les distinguer de codes aléatoires.
En effet, il suffit de calculer la dimension de  leur $hull$ puis de le comparer au résultat de la proposition \ref{dim_hull}.
Pour résoudre ce problème, nous poserons $q=3$ pour toute la suite du rapport.
Nous utiliserons également une nouvelle famille de codes, les codes $(U,U+V)$-généralisés :\\
\begin{defi} \label{UV-normalise} (codes $(U,U+V)$-généralisés) Soient $n$ un entier pair et $a$,$b$,$c$,$d$ quatres vecteurs de $\F_q^{n/2}$ tels que pour tout $i \in \llbracket 1,n/2\rrbracket$ :
\begin{equation}\label{ac}
a_ic_i \neq 0 
\end{equation}
\begin{equation}\label{ad-bc}
a_id_i - b_ic_i \neq 0 
\end{equation}

Soient U et V deux codes définis comme précédemment. Le code $(U,U+V)$-généralisé correspond à l'ensemble :
\begin{center}
$\{(a.u + b.v, c.u + d.v)$ tel que $u \in U$ et $v \in V \}$
\end{center}
où $x.y$ est le produit coordonnée par coordonnée des $x_i$ et $y_i$.\\
\end{defi}


Les conditions sur les vecteurs $a$, $b$, $c$, $d$ permet de garantir que :
\begin{itemize}
\item[-] toutes les coordonnées de $u \in U$ apparaîtront deux fois, ce qui sera nécessaire pour utiliser la structure du code dans notre algorithme de décodage (par l'équation \eqref{ac}).
\item[-] la dimension du code $(U,U+V)$-généralisé sera la somme des dimensions des codes $U$ et $V$ (par l'équation \eqref{ad-bc}).
\end{itemize}

Sans perte de généralité, nous posons pour toute la suite les vecteurs $a$,$b$,$c$,$d$ tels que $a_id_i - b_ic_i = 1 \text{ pour tout } i \in \llbracket 1,n/2\rrbracket$. \\

\begin{propo} Soient $U$, $V$, $a$, $b$, $c$ et $d$ définis comme précédemment. Soit $UV$ le code $(U,U+V)$-généralisé associé. Alors
$$ k = \dim\; (UV) = k_U + k_V.$$
De plus soient $G_U \in \F_q^{k_u \times n/2}$ (respectivement $G_V \in \F_q^{k_v \times n/2}$) et $H_U \in \F_q^{(n/2-k_u) \times n/2}$ (respectivement $H_V \in \F_q^{(n/2-k_v) \times n/2}$) les matrices génératrices et de parité des codes $U$ et $V$. Soient $A$, $B$, $C$, $D$ de $\F_q^{n \times n}$ les matrices diagonales de diagonale respectives les vecteurs $a$, $b$, $c$ et $d$.  \\
\vspace{0.2in}
Alors la matrice de $\F_q^{(k_u + k_v) \times n}$: 

\vspace{0.1in}

$$
G := 
\begin{pmatrix}
\begin{array}{c|c}
G_uA & G_uC \\
 \hline 
G_vB & G_VD \\
\end{array} \\
\end{pmatrix}
$$

\noindent et la matrice $\F_q^{(n - k_u - k_v) \times n}$:

\vspace{0.1in}
$$ 
H :=
\begin{pmatrix}
\begin{array}{c|c}
H_uD & -H_uB \\
 \hline 
-H_vC & H_VA \\
\end{array} \\
\end{pmatrix}
$$
\vspace{0.1in}

\noindent sont des matrices génératrices et de parité du code $UV$. 
\end{propo}

\begin{proof}[Preuve]
Remarquons d'abord que G engendre bien le code $UV$. Remarquons aussi que 

$$
G = 
\begin{pmatrix}
\begin{array}{c|c}
G_uA & G_uC \\
 \hline 
G_vB & G_VD \\
\end{array} \\
\end{pmatrix}
= 
\begin{pmatrix}
\begin{array}{c|c}
G_u & 0 \\
 \hline 
0 & G_V \\
\end{array} \\
\end{pmatrix} 
\begin{pmatrix}
\begin{array}{c|c}
A & C \\
 \hline 
B & D \\
\end{array} \\
\end{pmatrix}
$$

Par définition des matrices $G_V$ et $G_U$, la matrice $ 
\begin{pmatrix}
\begin{array}{c|c}
G_u & 0 \\
 \hline 
0 & G_V \\
\end{array} \\
\end{pmatrix} $ est de rang $k_U + k_V$. De plus les matrices $A$, $B$, $C$, $D$ étant diagonales, le déterminant de la matrice $\begin{pmatrix}
\begin{array}{c|c}
A & C \\
 \hline 
B & D \\
\end{array} \\
\end{pmatrix}$
est le produit des $(a_id_i - b_ic_i)$ pour $i \in {1, n/2}$, et donc non-nul par définition des vecteurs $a,b,c,d$. On a donc bien $k = k_U + k_V$. \\
On remarque aussi que $GH^T = 0$ et que $H$ est de rang plein par le même raisonnement que précédemment, ce qui conclut la preuve.
\end{proof}



\subsection{Le principe de signature}

Notre schéma de signature utilisera donc les codes $(U,U+V)$-généralisés et la fonction syndrome comme fonction à sens unique, sous l'hypothèse de la difficulté de résoudre le problème du décodage. \\

Nous allons définir la notion de fonctions GPV en moyenne (GPVM). Pour cela, introduisons d'abord la notion de distance statistique.

\begin{defi}
Soient $X$ et $Y$ deux variables aléatoires à valeurs dans le même espace $\epsilon$. 
Soient $\mathcal{D}_X$ et $\mathcal{D}_Y$ leurs distributions respectives. On définit la distance statistique entre ces deux distributions comme :
$$ \rho(\mathcal{D}_X,\mathcal{D}_Y) := \frac{1}{2} \sum_{x \in \epsilon} |\mathcal{D}_X(x) \mathcal{D}_Y(x)|.$$
\end{defi}

\begin{defi} (Fonctions GPVM). On appelle fonction GPV en moyenne une paire d'algorithmes (\verb|Trapdoor|,\verb|InvertAlg|) ainsi qu'un triplet de fonctions ($n(\lambda),k(\lambda),\omega(\lambda)$) en fonction d'un paramètre de sécurité $\lambda$, tels que :
\begin{itemize}
\item \verb|Trapdoor| est un algorithme probabiliste et polynomial en $1^\lambda$ et renvoyant le couple $(H,T)$ où $H \in \F_q^{(n-k) \times n}$ de rang $n-k$ et $T$ est la trappe associée.
\item \verb|InvertAlg| est un algorithme probabiliste et polynomial prenant en entrée la trappe $T$ et un syndrôme $s \in \F_q^{n-k}$, et renvoyant $e \in \F_q^{n}$ de poids $\omega$ tel que $eH^T = s$.
\end{itemize}
De plus, pour \textit{presque toutes} matrice $H$ renvoyée par \verb|Trapdoor|, la fonction est :
\begin{enumerate}
\item bien distribuée : \\
$\rho(eH^T,s) \in \text{negl}(\lambda)$ où $e$ est pris uniformément dans l'ensemble des mots de poids $\omega$ et de longueur $n$ et $s$ est pris uniformément dans $\F_q^{n-k}$. 
\item sans fuite d'information \textit{en moyenne} : \\
$ \rho(\verb|InvertAlg|(s,T),e) \in \text{negl}(\lambda)$ où $e$ est pris uniformément dans l'ensemble des mots de poids $\omega$ et de longueur $n$ et $s$ est pris uniformément dans $\F_q^{n-k}$. 
\item \`A sens unique sans la trappe : \\
Pour tout algorithme probabiliste polynomial $\mathcal{A}$, on a 
$$\mathbb{P}(\mathcal{A}(H,s) = e \;| \;eH^T = s) \in \text{negl}(\lambda).$$
\end{enumerate}
C'est une définition relaxée des fonctions GPV.
\end{defi}

Nous pouvons maintenant définir notre système de signature.
\begin{multicols}{2}
\begin{flushleft}
$\verb|Sign|^{sk}(s)$:\\
	$\quad$ e $\leftarrow$  \verb|InvertAlg|(s,T) \\
	$\quad$ \verb|renvoie| e
\end{flushleft}
\begin{flushleft}
$\verb|Verify|^{pk}(s,e')$: \\
	$\quad \verb| Si | e'H^T = s \verb| et | |e'| = \omega $ \\
	$\quad \quad$ \verb|renvoie 1| \\
	$\quad$ \verb|renvoie 0|
\end{flushleft}
\end{multicols}

EXPLIQUER POURQUOI LE SYSTÈME FONCTIONNE.

\subsection{Le décodage avec trappe}

En partant de l'hypothèse que la matrice de parité $\mathbf{H}$ du code $(U,U+V)$-généralisé ressemble à une matrice aléatoire, la difficulté de créer une fausse signature sans connaître la trappe $\mathbf{T}$ est exactement celle de résoudre le problème du décodage d'un code aléatoire, que l'on sait difficile. Nous allons expliciter dans cette section l'algorithme d'inversion de la fonction syndrome connaissant la trappe, et discuter de sa difficulté en fonction du poids $\omega$ de $\e$. \\

\noindent Notons $\mathcal{S}_{\omega,n}$ l'ensemble des mots de poids $\omega$ et de longueur $n$. On notera dans la suite $\mathcal{S}_{\omega}$ s'il n'y a pas d’ambiguïté sur la longueur. On rappelle que l'algorithme \verb|InvertAlg| cherche à inverser la fonction syndrome : 
$$\begin{array}{ccccc}
f_{\omega,\mathbf{H}} & : & \mathcal{S}_{\omega,n} & \to & \F_q^{n-k} \\
 & & \mathbf{e} & \mapsto & \mathbf{eH^T} \\
\end{array}$$

\noindent On rappelle que la fonction $f_{\omega,\mathbf{H}}$ avec $\mathbf{H} \in \F_q^{(n-k)\times n}$ s'inverse génériquement si $\omega \in \{\omega_{easy}^-,\omega_{easy}^+\}$, où :
$$ \omega_{easy}^- := \frac{q-1}{q}(n-k) \qquad \text{ et }\qquad  \omega_{easy}^+ := k + \frac{q-1}{q}(n-k).$$

\begin{proof}[Preuve] TODO
\end{proof}


\noindent On rappelle aussi que la fonction $f_{\omega,\mathbf{H}}$ admet un inverse pour toute entrée $s \in \F_q^{n-k}$ si $\omega \in \{\omega^-,\omega^+\}$, où :
$$\omega^- := \min\left\{\omega\in \llbracket0,n\rrbracket , \dbinom{\omega}{n}(q-1)^{\omega} \geq q^{n-k}\right\} $$
$$\omega^+ := \max\left\{\omega\in \llbracket0,n\rrbracket , \dbinom{\omega}{n}(q-1)^{\omega} \geq q^{n-k}\right\}$$

\begin{proof}[Preuve] TODO
\end{proof}


\noindent Nous voulons donc un moyen d'inverser la fonction syndrome pour $\omega \in \llbracket\omega_{UV}^-,\omega_{UV}^+\rrbracket$ avec $\omega_{UV}^-$ et $\omega_{UV}^+$ tels que :

$$\llbracket\omega_{easy}^-,\omega_{easy}^+\rrbracket \subsetneq \llbracket\omega_{UV}^-,\omega_{UV}^+\rrbracket \subset  \llbracket\omega^-,\omega^+\rrbracket$$


\noindent Afin d'expliciter le décodage, introduisons la fonction :

$$\begin{array}{ccccc}
\varphi_{\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}} & : & \F_q^{n/2} \times  \F_q^{n/2} & \to & \F_q^{n/2} \times  \F_q^{n/2} \\
 & & (\mathbf{x} , \mathbf{y}) & \mapsto &  (\mathbf{a}.\mathbf{x} + \mathbf{b}.\mathbf{y}, \mathbf{c}.\mathbf{x} + \mathbf{d}.\mathbf{y}) \\
\end{array}$$

\noindent Si cette fonction respecte les conditions sur les vecteurs $\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}$ définies dans la définition \ref{UV-normalise}, on dit qu'elle est UV-normalisée. Dans ce cas on peut vérifier qu'elle est bijective d'inverse :

$$\begin{array}{ccccc}
\varphi^{-1}_{\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}} & : & \F_q^{n/2} \times  \F_q^{n/2} & \to & \F_q^{n/2} \times  \F_q^{n/2} \\
 & & (\mathbf{x} , \mathbf{y}) & \mapsto &  (\mathbf{d}.\mathbf{x} - \mathbf{b}.\mathbf{y}, -\mathbf{c}.\mathbf{x} + \mathbf{a}.\mathbf{y}) \\
\end{array}$$

\noindent Ainsi, pour chaque vecteur $\mathbf{e}$ de $\F_q^n$, on peut associer deux vecteurs $\mathbf{e_U}$ et $\mathbf{e_V}$ de $\F_q^{n/2}$ tels que 
$$ (\mathbf{e_U},\mathbf{e_V}) = \varphi^{-1}_{\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}}(\mathbf{e}).$$

\begin{propo} Inverser $f_{\omega,\mathbf{H}}$ pour un certain $\mathbf{s} \in F_q^{n-k}$ est équivalent à trouver $\mathbf{e} \in \F_q^n$ tel que:
$$ \mathbf{e}_U\mathbf{H}_U^T = \mathbf{s}^U \qquad \text{et} \qquad \mathbf{e}_V\mathbf{H}_V^T = \mathbf{s}^V $$
où $\mathbf{s} = (\mathbf{s}^U, \mathbf{s}^V)$ avec $\mathbf{s}^U \in \F_q^{n/2-k_U}$ et $\mathbf{s}^V \in \F_q^{n/2-k_V}$.
\end{propo}

\begin{proof}[Preuve] TODO
\end{proof}

Ainsi, on on aura : \\
\begin{flushleft}
\leftskip=2cm
\verb|InvertAlg|$(\mathbf{s},\mathbf{T}) : $\\
$\qquad (\mathbf{s}_U, \mathbf{s}_V) = s $\\
$\qquad \mathbf{e}_U = \verb|DECODE_U|(\mathbf{s}_U) $\\
$\qquad \mathbf{e}_V = \verb|DECODE_V|(\mathbf{s}_V)$ \\
$\qquad \verb|renvoie | \varphi_{\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}}(\mathbf{e_U},\mathbf{e_V})$ \\
\leftskip=0cm
\vspace{0.1in}

\end{flushleft}
Si l'on choisit un algorithme générique pour \verb|DECODE_U| et \verb|DECODE_V|, alors nous obtiendrons un vecteur $\mathbf{e}$ de poids $\omega \ in \{\omega_{easy}^-,\omega_{easy}^+\}$. Non allons montrer comment utiliser les propriétés des codes $(U,U+V)$-généréralisés pour permettre un décodage hors de cet intervalle. 

\begin{remarque} Pour tout $\mathbf{e} = \varphi_{\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}}(\mathbf{e_U},\mathbf{e_V})$, on a pour tout $i \in \{1,n/2\}$ :
\begin{center}

$\left \{
\begin{array}{rcl}
a_i\mathbf{e}_U(i) + b_i\mathbf{e}_V(i) &=& \mathbf{e}(i) \\
c_i\mathbf{e}_U(i) + d_i\mathbf{e}_V(i) &=& \mathbf{e}(i+n/2) 
\end{array}
\right.$
\end{center}

Choisir la valeur de $\mathbf{e}_U$ en fonction de la valeur de $\mathbf{e}_V$ nous permettras donc d'influer sur le poids de $\mathbf{e}$. On aura alors :

\begin{flushleft}
\leftskip=2cm
\verb|InvertAlg|$(\mathbf{s},\mathbf{T}) : $\\
$\qquad (\mathbf{s}_U, \mathbf{s}_V) = s $\\
$\qquad \mathbf{e}_V = \verb|DECODE_V|(\mathbf{s}_V)$ \\
$\qquad \mathbf{e}_U = \verb|DECODE_U|(\mathbf{s}_U, \mathbf{e}_V) $\\
$\qquad \verb|renvoie | \varphi_{\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}}(\mathbf{e_U},\mathbf{e_V})$ \\
\leftskip=0cm
\vspace{0.1in}
\end{flushleft}

\end{remarque}

\begin{propo} Soit $\mathbf{e}_V$ une sortie de \verb|DECODE_V|. Soit \verb|DECODE_U| un algorithme prenant en entrée $\mathbf{s}_U$ et $\mathbf{e}_V$ et renvoyant $\mathbf{e}_U$ tel que $\mathbf{e}_U\mathbf{H}_U^T = \mathbf{s}^U$ et tel que pour $k_U$ positions de $\mathbf{e}_U$ 
\begin{center}
$\left \{
\begin{array}{rcl}
a_i\mathbf{e}_U(i) + b_i\mathbf{e}_V(i) &\neq& 0 \\
c_i\mathbf{e}_U(i) + d_i\mathbf{e}_V(i) &\neq& 0
\end{array}
\right.$
\end{center}
Alors $\mathbf{e} = \varphi_{\mathbf{a},\mathbf{b},\mathbf{c},\mathbf{d}}(\mathbf{e_U},\mathbf{e_V})$ a au moins $2k_U$ coordonnées non nulles. De plus les $n-k_U$ autres coordonnées sont uniformément distribuées sur $\F_q$. \\
On a alors 
$$ \mathbb{E}(|\mathbf{e}|) = \frac{q-1}{q}n + \frac{2k_U}{q} $$
et on peut alors espérer obtenir en temps polynomial des erreurs de poids:
\begin{center}
$\omega^+_{UV} = $
$\left \{
\begin{array}{rcl}
&\frac{q-1}{q}n + \frac{2k}{q} & \;\; \text{ si } k \leq n/2 \\
&n & \quad \text{sinon}
\end{array}
\right.$
\end{center}
\end{propo}

\begin{proof}[Preuve]
TODO
\end{proof}


\begin{propo} Soit $\mathbf{e}_V$ une sortie de \verb|DECODE_V|. Soit \verb|DECODE_U| un algorithme prenant en entrée $\mathbf{s}_U$ et $\mathbf{e}_V$ et renvoyant $\mathbf{e}_U$ tel que $\mathbf{e}_U\mathbf{H}_U^T = \mathbf{s}^U$ et tel que pour $k_U$ positions de $\mathbf{e}_U$ 
\begin{equation}\label{syst petit poid}
\left \{
\begin{array}{rcl}
a_i\mathbf{e}_U(i) + b_i\mathbf{e}_V(i) &=& 0 \\
c_i\mathbf{e}_U(i) + d_i\mathbf{e}_V(i) &=& 0
\end{array}
\right.
\end{equation}
On peut alors espérer obtenir en temps polynomial des erreurs de poids:
\begin{center}
\begin{equation} 
\omega^-_{UV} = 
\left \{
\begin{array}{rcl}
&\frac{q-1}{q}(n-2k) & \;\; \text{ si } k \leq n/(2q) \\
&\frac{2(q-1)^2}{(2q-1)q}(n-k) & \quad \text{sinon}
\end{array}
\right.
\end{equation}
\end{center}
\end{propo}

\begin{proof}[Preuve]
Il n'existe de solution au système (\ref{syst petit poid}) que si $\e_V(i)=0$ car pour tout $i$ on a $a_id_i -b_ic_i \neq 0$. De ce fait, à l'inverse du cas où nous souhaitions des erreurs de gros poids, l'ensemble d'indices où l'on peut gagner deux fois est réduit à $n/2 - |\e_V|$. De ce fait le poids minimal que nous pouvons espérer pour $\e_V$ est $|\e_V|_{min} := \frac{q-1}{q}(n/2-k_V)$. Ainsi :
\begin{itemize}
\item Si $k_U \leq n/2 - |\e_V|_{min}$, nous pouvons obtenir des erreurs $e$ telles que :
	\begin{itemize}
	\item $2k_U$ coordonnées sont nulles.
	\item Les autres coordonnées sont uniformément distribuées.
	\end{itemize}
\item Sinon, nous pouvons obtenir des erreurs $e$ telles que :
	\begin{itemize}
	\item $2(n/2 - |\e_V|_{min})$ sont nulles.
	\item $k_U - (n/2 - |\e_V|_{min})$ autres coordonnées sont nulles tandis que $k_U - (n/2 - |\e_V|_{min})$ sont non nulles.
	\item Les autres coordonnées sont uniformément distribuées.
	\end{itemize}
\end{itemize} 
PREUVE À DÉTAILLER
\end{proof}

On récapitule les différents cas dans la figure \ref{graphique ratio}. \\

\begin{figure}[h]
\begin{center}
\includegraphics [scale=0.4]{include/graph_ratio_w.png}
\end{center}
\caption{\small Comparaison des distances $w/n$ avec et sans trappe en fonction du rendement.}
\label{graphique ratio}
\end{figure}

La connaissance de la trappe apporte donc bien un avantage puisqu'elle permet un décodage pour des erreurs de poids ne permettant pas de décodage générique. 

\begin{remarque} Fonction de hachage
À FAIRE
\end{remarque}

\subsection{Implémentation et choix de paramètres}
TODO \\
\section{Uniformisation des signatures et syndromes}

\subsection{Une fuite d'information}
Afin d'assurer la sécurité du système, il est nécéssaire que les $\mathbf{e} \in f_{w,\mathbf{H}}^{-1}(\mathbf{s})$ ne révèlent pas d'information sur la structure du code (U,U+V)-généralisé utilisé. \\
Or, si la sortie $\mathbf{e_V}$ de \verb|DECODE_V| n'est pas uniforme, alors des corrélations entre les coordonnées $\mathbf{e}_i$ et $\mathbf{e}_{i+n/2}$ du vecteur $\mathbf{e}$. \\
Par exemple, prenons le cas où $q=3$, et où pour tout $i \in \{1,n/2\}$, $a_i = c_i = d_i = 1$ et $b_i = 0$, et où \verb|DECODE_V| est l'algorithme de Prange. \\
On a alors pour tout $\mathbf{e} = (\mathbf{e_U},\mathbf{e_U}+\mathbf{e_V})$
$$ |\mathbf{e_V}| = \# \; \{1  \leq i \leq n/2 \;|\; e_i \neq e_{i+n/2}\}$$

\begin{propo}
Si le vecteur $\mathbf{e_V}$ est obtenu par l'algorithme de Prange, alors il est de poids moyen $\frac{2}{3}(\frac{n}{2}-k_V)$.
\end{propo}

\begin{proof}[Preuve]
TODO
\end{proof}

Alors, pour tout $i \ in \{1,n/2\}$, on a :
$$ \mathbb{P}(\mathbf{e}_i \neq \mathbf{e}_{i+n/2}) = \frac{2}{3(n/2)}(n/2-k_V)(1+o(1))$$
PREUVE \\
En revanche, pour les autres paires $(i,j)$, on a :
$$ \mathbb{P}(\mathbf{e}_i \neq \mathbf{e}_{j}) = \frac{4wn - 3w^2-w}{n(n-1)}$$
PREUVE \\
Ces deux probabilités n'ont donc aucune raison d'être égales. On a donc une fuite d'information. En effet, dans la pratique et afin de cacher la structure, on effectue une permutation sur les coordonnées de $\mathbf{e}$ lors de la signature. Si un attaquant récupère suffisemment de signatures, il pourra donc en analysant la fréquence des $\mathbf{e}_i \neq \mathbf{e}_j$ retrouver cette permutation. Il est donc nécéssaire pour la sécurité du schéma de s'assurer de l'uniformité des sorties de l'algorithme \verb|sign|.

\subsection{La méthode du rejet}
Afin de s'assurer un $\mathbf{e}$ uniforme dans son ensemble, nous allons :
\begin{itemize}
\item choisir $\mathbf{e}_V$ de façon a ce qu'il soit uniforme dans son ensemble 
\item mettre des conditions de rejet sur $\mathbf{e}_U$ en fonction du poids de $\mathbf{e}_V$ afin de supprimer le biais sur l'ensemble 
$$ m_1(x) := \# \; \{1  \leq i \leq n/2 \;;\; |(x_i, x_{i+n/2})| = 1\}$$
\end{itemize}
Avant d'expliciter nos algorithmes, il est nécéssaire d'introduire quelques notations et définitions. \\

\begin{nota} On notera :
\begin{itemize}
\item $\mathbf{e}^{unif}$ la variable aléatoire tirée uniformément dans l'ensemble $S_{w,n}$
\item $\mathbf{e}_V^{unif}$ la variable aléatoire tirée uniformément dans les mots de $\F_q^{n/2}$ 
\item $\mathbf{e}_U^{unif}$ la variable aléatoire tirée uniformément dans les mots de $\F_q^{n/2}$ conditionné au vecteur $\e_V^{unif}$
\end{itemize}
\end{nota}


\begin{defi} (uniforme en poids et $m_1$-uniforme)
\begin{itemize}
\item \verb|DECODE_V| est dit uniforme en poids si ces sorties $\mathbf{e}_V$ sont telles que $\mathbb{P}(\mathbf{e}_V)$ n'est fonction que du poids de $\mathbf{e}_V$ quand $\mathbf{s}^V$ est tiré uniformément dans son ensemble.
\item \verb|DECODE_U| est dit $m_1$-uniforme si ces sorties $\mathbf{e}_U$ sont telles que $\mathbb{P}(\mathbf{e}_U\; |\;  \mathbf{e}_V)$ n'est fonction que du poids de $\mathbf{e}_V$ et de $m_1(\varphi(\mathbf{e}_U,\mathbf{e}_V))$.
\end{itemize}
\end{defi}

\begin{lemme} Soit $\mathbf{e}$ la sortie de \verb|InvertAlg| avec $\mathbf{s}_U$ et $\mathbf{s}_V$ choisis uniformément dans leurs ensembles. Soit \verb|DECODE_V| uniforme en poids et \verb|DECODE_U| $m_1$-uniforme. Si pour tout $y$ et $z$ 
$$|\mathbf{e}_V| \sim |\mathbf{e}_V^{unif}|\quad \text{et} \quad\mathbb{P}(m_1(\mathbf{e}) = z\; |\; |\mathbf{e}_V| = y) = \mathbb{P}(m_1(\mathbf{e}^{unif}) = z\; |\; |\mathbf{e}_V^{unif}| = y)$$
Alors
$$ \mathbf{e} \sim \mathbf{e}_V^{unif}.$$
\end{lemme}

\begin{proof}[Preuve]\
Nous allons montrer qu'avec les hypothèses précédentes nous avons $\forall x \in S_{\omega} \quad \mathbb{P}(\e = x) = \mathbb{P}(\e^{unif} = x)$.\\
Soit $x \in S_{\omega}$ :
\begin{equation*}
\begin{split}
\mathbb{P}(\e = x) &= \mathbb{P}(\e_U = x_U, \e_V = x_V)\\
&= \mathbb{P}(\e_U = x_U | \e_V = x_V)\mathbb{P}(\e_V = x_V)\\
\end{split}
\end{equation*}
Notre but étant de faire apparaître les expressions énoncées lors du lemme, nous allons exprimer ces deux probabilités en fonction de $|x_V| = y$ et de $m_1(x) = z$.
\begin{equation*}
\begin{split}
\mathbb{P}(\e_V = x_V) &= \mathbb{P}(\e_V = x_V, |\e_V| = y)\\
&= \left.\mathbb{P}(\e_V = x_V \right| |\e_V| = y)\ \mathbb{P}(|\e_V| = y)\\
&= \frac{\mathbb{P}(|\e_V| = y)}{n(y)}\\
\end{split}
\end{equation*}
avec $n(y) := \#\left\{ \left.\e \in \F_3^{n/2} \right| |e| = y\right\}$.
De la même façon, nous obtenons :
\begin{equation*}
\begin{split}
\mathbb{P}(\e_U = x_U |\ |\e_V| = y) &= \left.\mathbb{P}(\e_U = x_U ,\ m_1(\e) = z\ \right|\ |\e_V| = y)\\
&= \left.\mathbb{P}(\e_U = x_U\ \right|\ m_1(\e) = z,\ |\e_V| = y)\mathbb{P}(m_1(\e) = z\ |\ |\e_V| = y)\\
&= \frac{\mathbb{P}(m_1(\e) = z\ |\ |\e_V| = y)}{n(y,z)}\\
\end{split}
\end{equation*}
avec $n(y,z) := \#\left\{ \left.\e \in \F_3^{n/2} \right|\  m1(\e) = z\text{ et } |\e_V| = y \right\}$.\\
Ainsi nous obtenons
\begin{equation*}
\begin{split}
\mathbb{P}(\e = x) &= \frac{\mathbb{P}(m_1(\e) = z\ |\ |\e_V| = y)}{n(y,z)}\frac{\mathbb{P}(|\e_V| = y)}{n(y)}\\
 &= \frac{\mathbb{P}(m_1(\e^{unif}) = z\ |\ |\e_V^{unif}| = y)}{n(y,z)}\frac{\mathbb{P}(|\e_V^{unif}| = y)}{n(y)}\\
 &\quad \text{par les hypohèses}\\
 &= \mathbb{P}(\e_U^{unif} = x_U | \e_V^{unif} = x_V)\mathbb{P}(\e_V^{unif} = x_V)\\
 &= \mathbb{P}(\e^{unif} = x)\\
\end{split}
\end{equation*}
\end{proof}


Ainsi, pour que $\mathbf{e}$ soit uniformément distribué sur $S_\omega$, il suffit de choisir \verb|DecodeV| de façon à ce que ses sorties soient uniforment sur $\F_q^{n/2}$ puis d'ajouter une condition de rejet sur les sorties de \verb|DecodeU| de façon à ce que $m_1(\mathbf{e})$ conditionnée à $|\mathbf{e}_V|$ soit distribué comme $m_1(\mathbf{e}^{unif})$ conditionnée à $|\mathbf{e}_V^{unif}|$. \\
On peut alors introduire l'algorithme suivant :
\begin{algorithm}
	\caption{DecodeUV($\varphi, \s, \mathbf{H}_V, \mathbf{H}_U$)}
	\begin{algorithmic}[1]
   	 	\REQUIRE $\varphi$, $\s \in \F_q^{n-k}$ un syndrome, $\mathbf{H}_V \in \F_q^{(\frac{n}{2} - k_V) \times \frac{n}{2}}$, $\mathbf{H}_U \in \F_q^{(\frac{n}{2} - k_U) \times \frac{n}{2}}$
   	 	\ENSURE $\e = \varphi(e_U, e_V) \text{ avec } \e_U\mathbf{H}_U^T = \s^U \text{ et } \e_V\mathbf{H}_V^T = \s^V$
    	\STATE $\e_V \leftarrow \text {DecodeV}(\s^V,\mathbf{H}_V)$
    	\REPEAT 
    	\STATE $\e_U \leftarrow \text {DecodeU}(\varphi, \e_V, \s^U, \mathbf{H}_U)$
    	\STATE $\e \leftarrow \varphi(\e_U,\e_V)$
    	\UNTIL {$\text{rand}([0,1]) > \mathbf{r}_U(|\e_V|, m_1(\e)$}
    	\RETURN $\e$
    \end{algorithmic}
\end{algorithm}\


\noindent Avec :

\begin{equation*}
   \begin{split}
    r(s,t) &:= \frac{1}{M(t)}\frac{q^{unif}(s,t)}{q(s,t)} \\
    q(s,t) &:= \mathbb{P}(m_1(\mathbf{e})=s\;|\;|\mathbf{e}_V|=t)\\[.6cm]
    q^{unif}(s,t) &:= \mathbb{P}(m_1(\mathbf{e}^{unif})=s\;|\;|\mathbf{e}^{unif}_V|=t)\\[.6cm]
    M(t) &:= \max_{0 \leq s \leq t} \frac{q^{unif}(s,t)}{q(s,t)}\\[.6cm]
    \end{split}
\end{equation*}
On peut alors énoncer la proposition suivante :


\begin{propo}
Si \verb|DecodeV| est uniforme en poids et si \verb|DecodeU| est $m_1$-uniforme, alors on a $\mathbf{e}\sim\mathbf{e}^{unif}$.
\end{propo}

\begin{proof}[Preuve]
Soit $\e_U'$ le vecteur obtenu à la sortie de la boucle dans \verb|DECODE_UV|. On remarque que pour tout $i,j$:
$$0 \leq r(i,j) = \frac{1}{M(i,j)}\frac{q^{unif}(i,j)}{q(i,j)} = \Bigg(\inf_{0 \leq k \leq l}\frac{q(k,l)}{q^{unif}(k,l}\Bigg)\frac{q^{unif}(i,j)}{q(i,j)} \leq 1$$
Donc les coordonnées de $r$ sont bien des probabilités. Notons pour tout $i,j \in \llbracket 1,n \rrbracket$:
$$q'(i,j) := \mathbb{P}(m_1(\mathbf{e'}_U)=i\;|\;|\mathbf{e'}_V|=j)$$

On a alors 
\begin{equation}
\begin{aligned}
q'(i,j) &= \frac{r(i,j)q(i,j)}{\sum_{0 \leq k \leq l}r(k,l)q(k,l)} \\
 &= \frac{q^{unif}(i,j)}{M(i,j)\sum_{0 \leq k \leq l}\frac{1}{M(k,l)}q^{unif}(l)} \\
 &= q^{unif}(i,j) \\
\end{aligned}
\end{equation}
La première ligne vient de l'indépendance du tirage du réel rand($[0,1]$) du poids de $\e_V$ et de $m_1(\e)$. La dernière ligne vient du fait que la somme sur $i,j$ des $q^{unif}(i,j)$ vaut $1$. De plus la sortie de l'algorithme \verb|DECODE_V| est uniforme, ce qui conclu la preuve.
\end{proof}

\subsection{Choix des algorithmes de décodage}
description explicite de \verb|DECODE_V| \\
description explicite de \verb|DECODE_U| \\
Application de la méthode du rejet selon ces choix et choix des distributions. 

\subsection{Estimation du nombre de rejet}


\begin{algorithm}
	\caption{DecodeU($\varphi, \e_V, \s^U, \mathbf{H}_U$)}
	\begin{algorithmic}[1]
		\STATE $t \leftarrow |\e_V|$
		\STATE $k_0 \hookleftarrow \mathcal{D}_U^t$
		\REPEAT
		\STATE $\mathcal{I} \leftarrow$ ensemble d'information de $\langle\mathbf{H}\rangle^\perp$
		\STATE $\mathcal{J} \subset \mathcal{I}$ de taille $k-d$ tel que $|\e_V|_\mathcal{J} = k_0$
		\STATE $x_U \hookleftarrow \{x\in\F_3^{n/2} | \forall j\in\J,  x_j \notin \{-\frac{b_i}{a_i}\e_{V_i}, -\frac{d_i}{c_i}\e_{V_i}\}\}$
		\STATE $\e_U \leftarrow \textsc{Prange }(\mathbf{H}_U, \s^U, \mathcal{I}, x_U)$
		\UNTIL {$|\varphi(\e_U,\e_V)| \neq \omega$}
		\RETURN $\e_U$
    \end{algorithmic}
\end{algorithm}


\begin{algorithm}
	\caption{DecodeV($\s^V$)}
	\begin{algorithmic}[1]
    	\STATE $c$ mot aléatoire du code $V$
    	\STATE $\s \leftarrow$ le syndrome $\s^V$ paddé avec des zéros
    	\STATE $\e_V \leftarrow \s + c$
    	\RETURN $\e_V$
    \end{algorithmic}
\end{algorithm}

EXPLIQUER POURQUOI ON AJOUTE LE $d$.\\
Avec $d\in [0,k_U]$, qui permettra de montrer que notre sortie est uniforme.

\begin{defi} (Bon ensemble).
Soient $d \leq k \leq n$, $\mathbf{H}\in\F_3^{(n-k)\times n}$ et $\varepsilon \subseteq \llbracket1,n\rrbracket$ de taile $k-d$. On dit que $\varepsilon$ est un bon ensemble pour $\mathbf{H}$ si $\mathbf{H}_{\overline{\varepsilon}}$ est de rang plein. Sinon, on dit que $\varepsilon$ est un mauvais ensemble.
\end{defi}


Nous voulons compter le nombre de rejets moyen, pour cela nous allons comparer $\e$ la sortie de \verb|DecodeUV| avec $\e^{unif}$ une erreur aléatoire uniforme de poids $\omega$.\\
Nous savons dores et déjà que la sortie de \verb|DecodeV| est uniforme, nous allons donc étudier la sorite de \verb|DecodeU|.
Nous introduisons pour cela \verb|VarDecodeU| qui fonctionne de la même façon que \verb|DecodeU| quand $\J$ est un bon ensemble pour $\mathbf{H}$ et qui renvoie une erreur aléatoire selon la distribution $\D_U^t$ sur $\J$ dans le cas contraire.
Il n'y a donc aucune raison que la sortie soit une solution du problème de décodage lorsque $\J$ n'est pas un bon ensemble pour $\mathbf{H}$.
Nous pouvons facilement voir que \verb|VarDecodeU| est $m_1$-uniforme.\\
La sortie de l'algorithme \verb|DecodeUV| utilisant \verb|VarDecodeU| est alors uniforme, on la note $\e^{unif}$.\\

\begin{defi}\
\begin{itemize}
\item $J_{x_V,l}^{unif}$ et un ensemble choisi uniformément tel que $J_{x_V,l}^{unif}\subseteq \llbracket 1,n/2 \rrbracket$, il est de cardinal $k_U-d$ et $\#J_{x_V,l}^{unif}\cap Supp(x_V) = k_0$. 
\item $J_{x_V, l}^{\mathbf{H}_U}$ est défini de la même façon avec une contrainte supplémentaire : il fait parti des bons ensembles pour $\mathbf{H}_U$.
\end{itemize}
\end{defi}

Pour pouvoir compter le nombre de rejets, nous allons avoir besoin des lemmes suivants dont les preuves sont en annexes.

\begin{lemme}\label{maj_dist_e_eunif}
$$ \rho\left(\e ,\e^{unif}\right) \leq \sum\limits_{x_V,l} \rho\left(J_{x_v,l}^{\mathbf{H}_U},J_{x_v,l}^{unif}\right)\mathbb{P}\left(k_0 = l, \e_V = x_V\right) $$ 
\end{lemme}


\begin{lemme}
\begin{equation}\label{esp}
\mathbb{E}\left(\rho\left(J_{x_V,l}^{unif},J_{x_V, l}^{\mathbf{H}_U}\right)\right) \leq \frac{3^{-d}}{2}
\end{equation}

\end{lemme}

\begin{lemme}\label{markov}(Inégalité de Markov).\\
Soit $Z$ une variable aléatoire supposée presque sûremeny positive ou nulle, alors $$\forall a>0\quad \mathbb{P}(Z > a) \leq \frac{\mathbb{E}(Z)}{a}$$
\end{lemme}

Nous pouvons maintenant énoncer le théorème suivant :

\begin{thm}\label{rejet}
Soit $\e$ la sortie de \verb|DecodeUV| et $\e^{unif}$ la variable aléatoire uniformément distribuée parmi les mots de poids $\omega$. On a :
$$ \mathbb{P}\left(\rho(\e,\e^{unif})>3^{-d/2}\right) \leq \frac{3^{-d/2}}{2} $$
\end{thm}

\begin{proof}[Preuve]
\begin{equation*}
\begin{split}
\mathbb{P}&\big(\rho(\e,\e^{unif})>3^{-d/2}\big) \\
&\leq 3^{d/2}\mathbb{E}(\rho\left(\e,\e^{unif})\right) \quad \text{par l'inegalité de Markov}\\
&\leq 3^{d/2}\mathbb{E}\left(\sum\limits_{x_V,l} \rho\left(J_{x_v,l}^{\mathbf{H}_U},J_{x_v,l}^{unif}\right)\mathbb{P}\left(k_0 = l , \e_V = x_V\right)\right) \text{ d'après le lemme \ref{maj_dist_e_eunif}}\\
&\leq 3^{d/2}\left(\sum\limits_{x_V,l} \frac{3^{-d}}{2}\mathbb{P}\left(k_0 = l ,\e_V = x_V\right)\right) \quad \text{par \eqref{esp}}\\
&= 3^{d/2} \frac{3^{-d}}{2}\left(\sum\limits_{x_V,l}\mathbb{P}\left(k_0 = l ,\e_V = x_V\right)\right) \\
&= \frac{3^{-d/2}}{2}\\
\end{split}
\end{equation*}
\end{proof}


La probabilité d'avoir un rejet équivaut à la probabilité d'avoir une distance significative entre $\e$ et $\e^{unif}$. D'après le théorème \ref{rejet}, nous voyons donc qu'en faisant varier $d$, nous serons en mesure d'effectuer très peu de rejets.


\subsection{Une famille de fonctions uniformément distribuée}
On a donc le point (2) de la définition des fonctions GPV qui est obtenu dans la section précédente. On va montrer le point (1), à savoir, notre famille de fonctions syndromes est uniformément distribuée avec les codes (U,U+V)-généralisés. \\
TODO


\section{Sécurité du schéma}
Pour montrer la sécurité du schéma, nous allons dans un premier temps montrer que sous l'hypothèse que la matrice de parité du code considéré est difficile à distinguer d'une matrice aléatoire, le schéma est sûr au sens EUF-CMA.\\
Nous montrerons ensuite qu'il est effectivement difficile de distinguer notre matrice de parité permutée d'une matrice aléatoire. \\

\subsection{Sécurité EUF-CMA}
Nous allons montrer que le schéma est sûr au sens EUF-CMA (Existential Unforgeability under Chosen Message Attacks). Pour cela nous ferons une réduction au problème DOOM.
\subsubsection{Définitions}

Soit $\mathcal{A}$ un adversaire ayant accès à $N_{sign}$ signatures de son choix. Soit les trois algorithmes suivants :


\begin{algorithm} [h]
	\caption{Init($\lambda$)}
	\begin{algorithmic}[1]
    	\STATE $(pk,sk) \Longleftarrow$ Gen$(1^\lambda)$ 
    	\STATE $\mathbf{H}_{pk} \Longleftarrow pk$
    	\STATE $(\varphi,\mathbf{H}_{U},\mathbf{H}_{V})\Longleftarrow sk$
    	\RETURN $\mathbf{H}_{pk}$
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
	\caption{Sign($s$)}
	\begin{algorithmic}[1]
    	\STATE $\e \Leftarrow \mathcal{D}_{\varphi,\mathbf{H}_{U},\mathbf{H}_{V}}(\s)$
    	\RETURN $\e$
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
	\caption{Fin($(s,e)$)}
	\begin{algorithmic}[1]
    	\RETURN $(\mathbf{e}\mathbf{H}_{pk}^T = s) \land (|\mathbf{e}| = \omega)$
    \end{algorithmic}
\end{algorithm}

Le jeu EUF-CMA se déroule comme suit. $\mathcal{A}$ fait appel à \verb|Init|. Il peut ensuite faire $N_{sign}$ requêtes à \verb|sign|. Le jeu est dit réussi si $\mathcal{A}$ est capable de donner $(s,e)$ accepté par \verb|Fin| et tel que $s$ n'est jamais été demandé à \verb|Sign|. \\
On définit alors le succès EUF-CMA comme :
$$Succ^{EUF-CMA}_{Wave}(t,N_{sign}) := \max_{\mathcal{A};|A|\leq t}(\mathbb{P}(\mathcal{A}\text{ réussit le jeu EUF-CMA de Wave})).$$
Le protocole est alors sûr au sens EUF-CMA si ce succès est négligeable. \\

Nous souhaitons donc montrer que notre système est sûr au sens EUF-CMA. Pour cela, nous allons dans la section suivante majorer ce succès par rapport au succès d'un problème connu, le problème DOOM.


\subsubsection{Réduction au problème DOOM}
\textbf{Le problème DOOM.} Soient des paramètres $(n,q,k,\omega,N)$, où $N$ est un entier. \\

\leftskip=1cm
\noindent \textbf{I :} $\mathbf{H}$ une matrice uniforme de $\F_q^{(n-k)\times n}$ et $(\mathbf{s}_1,...,\mathbf{s}_N)$ une liste de $N$ syndromes. 

\noindent \textbf{Q :} Décoder l'un des syndromes à la distance $w := \lfloor \omega n \rfloor$. \\

\leftskip=0cm

\noindent On définit alors le succès de DOOM comme :
$$Succ^{DOOM(n,q,k,N)}(t) := \max_{\mathcal{A};|A|\leq t}(\mathbb{P}(\mathcal{A}(\mathbf{H},\mathbf{s}_1,...,\mathbf{s}_n)=\mathbf{e}\text{ tel que }$$
$$ \mathbf{eH}^T = \mathbf{s}_j \text{ pour un certain } j \in \{1,...,N\})).$$

\noindent La réduction à ce problème est naturelle pour un schéma de signature puisque EXPLICATION INFORMELLE DE LA REDUCTION, POURQUOI ELLE VA MARCHER \\


\subsubsection{Preuve formelle de la réduction}
Afin de faire une preuve formelle de la sécurité EUF-CMA, nous allons changer le jeu en rajoutant une fonction de hachage. L'attaquant $\mathcal{A}$ peut maintenant faire $N_{hash}$ appelle à la fonction de hachage et ainsi obtenir des couples (m,s). De plus, la fonction de signature prends maintenant en entrée un message quelconque. Elle prend ensuite un aléa $r$ dans $\{0,1\}^{\lambda_0}$. Le tout est alors donné à la fonction de hachage qui renvoit un syndrome valide. \\

Nous allons aussi introduire un système de jeux qui nous permettra de réduire la sécurité d'un système à un problème $P$. Soit $\mathcal{A}$ un attaquant et $\mathcal{R}$ un rival. Soient $G_0, G_1, ...,G_N$ un ensemble de jeux et soit $\mathbb{P}(G_i)$ la probabilité pour $\mathcal{A}$ de répondre au défi posé par $\mathcal{R}$ pour le jeu $G_i$. $\mathbb{P}(G_0)$ est alors la probabilité de cassé le système considérer et $\mathbb{P}(G_N)$ la probabilité de répondre au problème $P$. \\
L'idée est de changer pas à pas les jeux $G_0$ à $G_N$ de façon à ce que :
$$\forall i \in {0,...,N-1}, |\mathbb{P}(G_i)-\mathbb{P}(G_i+1)| \in negl(\lambda) \Longrightarrow |\mathbb{P}(G_0)-\mathbb{P}(G_N)|  \in negl(\lambda)$$
où $\lambda$ est un paramètre de sécurité. Autrement dis, les changements sur les jeux ne changent qu'à un facteur négligeable près les probabilités de succès de l'attaquant $\mathcal{A}$. \\
Il n'est pas possible de changer le comportement de $\mathcal{A}$ puisqu'il est quelconque, en revanche nous pouvons modifier celui de $R$. \\

\begin{thm} (Réduction de sécurité). \\
Soit $N_{sign}$ le nombre de requêtes faites à l'oracle de signature. Soit $\lambda$ le paramètre de sécurité et $\lambda_0=\lambda + 2\log_2(N_{sign})$. On a :
$$Succ^{EUF-CMA}_{Wave}(t,N_{sign}) \leq 2Succ^{DOOM(n,q,k,N)}(t) +\rho(\mathcal{D}_{rand},\mathcal{D}_{pub})(t) + $$
$$ f(\mathcal{U}_{\omega},\mathcal{D}_{\omega}^{\mathbf{H}_{pk}}) + g(\epsilon) + c + \frac{N_{hash}}{2}\sqrt{\epsilon} + \frac{1}{2^{\lambda}}$$
\end{thm}

\begin{proof}[Preuve] On rappelle que $G_0$ correspond à notre jeu pour la sécurité EUF-CMA de Wave.
\begin{itemize} 
\item $G_1$ : Le jeu $G_1$ est identique au jeu $G_0$ sauf si l'évènement 
\begin{center}
$F := \{\text{Un même aléa r a été tiré lors de deux requêtes}$
$\text{\qquad d'un même message à l'oracle de signature}\}.$
\end{center}
On a alors 
$$ \mathbb{P}(G_0) \leq  \mathbb{P}(G_1) +  \mathbb{P}(F) $$
Or pour $\lambda_0=\lambda + 2\log_2(N_{sign})$, la probabilité que l'évènement $F$ se produise est majorée par $\frac{1}{2^{\lambda}}$. C'est donc négligeable et le changement est autorisé.
\item $G_2$ : Le passage au jeu $G_2$ permet d'empêcher $\A$ de faire appel à l'oracle de signature sur les syndrome du problème DOOM. L'idée est de créer une liste suffisemment grande $L_m$ d'aléas tous différents. On modifie alors la fonction \verb|hash| de cette façon :
	\begin{enumerate}
	\item Si \verb|hash| est appelée par la fonction \verb|sign|, alors les aléas seront pris successivement dans $L_m$ et associés à un vecteur erreur $\e_{m,r}$ (stocké) pris uniformément dans $S_{\omega}$. Elle renvoie alors $\s=\e_{m,r}\mathbf{H}^T$.
	\item En revanche si \verb|hash| est appelée hors de la fonction \verb|sign| par $\A$, alors elle son comportement dépendra de l'aléa. Si $r$ est dans $L_m$ elle se comporte comme si elle avait été appelée par \verb|sign| et renvoie $\e_{m,r}\mathbf{H}^T$. Sinon elle renvoie successivement les syndromes du problème DOOM.
	\end{enumerate}
On prend donc dans la fonction \verb|sign| toujours le $r$ suivant de $L_m$. On a alors changé le jeu en supprimant le cas où deux mêmes $r$ sont tirés lors de la signature. Cela ne pose pas de problème grace au passage à $G_1$. Le passage au jeu $G_2$ permettra ainsi de s'assurer par la suite que $\A$ n'a pas fait d'appel à \verb|sign| sur les syndromes du problème DOOM.
On a alors 
$$ \mathbb{P}(G_1) \leq  \mathbb{P}(G_2) +  \frac{N_{hash}}{2}\sqrt{\epsilon} $$
où $\epsilon$ est une fonction en $n$ qui décroît exponentiellement. C'est donc bien négligeable.
\item $G_3$ : Le jeu $G_3$ permet à l'oracle de signature de se passer de l'algorithme de décodage, et donc de la trappe $T$. Il sera nécessaire pour remplacer la matrice du code (U,U+V)-généralisé par la matrice aléatoire de l'instance du problème DOOM. Pour passer au jeu $G_3$, on modifie la sortie de \verb|sign|. Au lieu de renvoyer le couple $(\e,r)$ où $\e = D_{\varphi,H_U,H_V}$, on renvoit le couple $(\e_{m,r},r)$ préalablement stocké.\\
 La différence de succès de dépand que de $\omega$ et des différence de distribution entre $\mathcal{U}_{\omega}$ et $\mathcal{D}_{\omega}^{\mathbf{H}_{pk}}$, où $\mathcal{U}_{\omega}$ et la distribution uniforme sur $S_{\omega}$ et où $\mathcal{U}_{\omega}$ et $\mathcal{D}_{\omega}^{\mathbf{H}_{pk}}$ est la distribution des couples $(e,r)$ où $r$ est un aléa uniforme dans $\{0,1\}^{\lambda_0}$ et $e$ est la sortie de l'algorothme de décodage avec trappe sur une entrée $s$ prise uniformément dans $\F_q^{n-k}$.
On a alors 
$$ \mathbb{P}(G_2) \leq  \mathbb{P}(G_3) + f(\mathcal{U}_{\omega},\mathcal{D}_{\omega}^{\mathbf{H}_{pk}}) + g(\epsilon) + c$$
où $f$ et $g$ sont linéaires et $c$ un certaine constante.
\item $G_4$ : On peut maintenant remplacer $\mathbf{H}_{pk}$ par $\mathbf{H}_0$. Ce changement ne pose pas de problème puisque \verb|sign| n'utilise plus la trappe. En revanche, nous avons créé un distingueur entre la distribution $(:=\mathcal{D}_{rand})$ des matrices prises aléatoirement dans $\F_q{(n-k)\times n}$ et la distribuction $(:=\mathcal{D}_{pub})$ des matrices prises aléatoirement dans l'ensemble des matrices de parité d'un code $(U,U+V)$-généralisé où $U$ (resp. $V$) est un $[n/2,k_U]$-code (resp. $[n/2,k_V]$-code). 
On a alors 
$$ \mathbb{P}(G_3) \leq  \mathbb{P}(G_4) + \rho(\mathcal{D}_{rand},\mathcal{D}_{pub})(t)$$
\item $G_5$ : On change ici la procédure de fin. On rajoute à la vérification la condition $r \notin L_m$. Ainsi on est bien sûr que $\A$ réussi le jeu s'il répond au problème DOOM. Alors la probabilité que $\A$ réussisse $G_5$ est exactement la probabilité que $\A$ réussisse $G_4$ et $r\notin L_m$.
On a alors 
$$ \mathbb{P}(G_4) \leq  2\mathbb{P}(G_5) + \rho(\mathcal{D}_{rand},\mathcal{D}_{pub})(t)$$
où $\mathbb{P}(G_5)$ est exactement la probabilité pour $\A$ de renvoyer $\e_j \in S_{\omega}$ et tel que $\e_j\mathbf{H}_0^T = \s_j$ pour un certain indice $j$ du problème DOOM. On a donc 
$$ \mathbb{P}(G_5) \leq Succ^{n,k,N_{hash}, \omega}_{DOOM}(t)$$
\end{itemize}
En rassemblant toutes les inégalités on termine la preuve. (On trouvera le détail des preuves de probabilité en annexe de ce rapport.)
\end{proof}


\subsection{Indistinguabilité des codes (U,U+V)-généralisés}
Distinguer une matrice de parité d'un code (U,U+V)-généralisé d'une matrice de parité aléatoire. \\
Réduction à un problème NP-complet. \\
Utilisation de S et P pour masquer les propriétés de la matrice. \\

\section*{Conclusion}
\addcontentsline{toc}{section}{\protect\numberline{}Conclusion}

\newpage



\section*{ANNEXES}
\addcontentsline{toc}{section}{\protect\numberline{}ANNEXES}
\begin{proof}[Preuve du lemme \ref{maj_dist_e_eunif}]
Nous allons avoir besoin dans la suite de la proposition suivante :
\begin{propo}\label{rho_f}
Soient $X$ et $Y$ deux variables aléatoires dans le même espace $A$ et $Z$ une variable aléatoire dans l'espace $B$ indépendante de $X$ et $Y$. Alors, pour toute fonction $f$, nous avons : $$ \rho(f(X,Z),f(Y,Z)) \leq \rho(X,Y)$$
\end{propo}

{\scriptsize
\begin{equation*}
\begin{split}
\rho(\e,\e^{unif}) &= \rho\Big((\e_U,\e_V),(\e_U^{unif},\e_V^{unif})\Big)\\
&\leq \sum\limits_{x_U,x_V} \left|\mathbb{P}\Big((\e_U,\e_V)=(x_U,x_V)\Big) - \mathbb{P}\Big((\e_U^{unif},\e_V^{unif})=(x_U,x_V)\Big)\right|\\
&= \sum\limits_{x_U,x_V} \left|\mathbb{P}(\e_V = x_V)\mathbb{P}(\e_U=x_U|\e_V=x_V) - \mathbb{P}(\e_V^{unif} = x_V)\mathbb{P}(\e_U^{unif}=x_U | \e_V^{unif}=x_V)\right|\\
&= \sum\limits_{x_U,x_V} \mathbb{P}(\e_V = x_V)\left|\mathbb{P}(\e_U=x_U|\e_V=x_V) - \mathbb{P}(\e_U^{unif}=x_U | \e_V^{unif}=x_V)\right|\\
\end{split}
\end{equation*}}

Étudions le terme  $\mathbb{P}(\e_U=x_U|\e_V=x_V) - \mathbb{P}(\e_U^{unif}=x_U | \e_V^{unif}=x_V)$:
{\scriptsize
$$ \mathbb{P}(\e_U=x_U|\e_V=x_V) - \mathbb{P}(\e_U^{unif}=x_U | \e_V^{unif}=x_V) =  $$
$$ \sum\limits_l \left[ \mathbb{P}(\e_U=x_U|k_0 = l,\e_V=x_V) - \mathbb{P}(\e_U^{unif}=x_U |k_0 = l, \e_V^{unif}=x_V) \right] \mathbb{P}\left(k_0 = l | \e_V =x_V\right)$$
}

Les ensembles $\J$ étant inclus dans un ensemble d'information, l'aléa interne de \verb|DecodeU| et de \verb|VarDecodeU| ne dépendent pas du choix de $J_{x_V,l}^{unif}$ et $J_{x_V, l}^{\mathbf{H}_U}$. \\
Nous pouvons voir que $\mathbb{P}(\e_U=x_U|k_0 = l,\e_V=x_V)$ ne dépend que de $x_U$ et $J_{x_V, l}^{\mathbf{H}_U}$ et   $\mathbb{P}(\e_U^{unif}=x_U |k_0 = l, \e_V^{unif}=x_V)$ ne dépend que de $x_U$ et $J_{x_V, l}^{unif}$. 
De plus, $J_{x_V,l}^{unif}$ et $J_{x_V, l}^{\mathbf{H}_U}$ vivent dans le même espace.
Ainsi d'après la proposition \ref{rho_f}, nous avons 
{\scriptsize
$$ \sum\limits_{x_U}\mathbb{P}(\e_U=x_U|k_0 = l,\e_V=x_V) - \mathbb{P}(\e_U^{unif}=x_U |k_0 = l, \e_V^{unif}=x_V)\quad \leq\quad \rho(J_{x_V, l}^{\mathbf{H}_U},J_{x_V, l}^{unif})$$
}


\begin{equation}
\rho\left(J_{x_V,l}^{unif},J_{x_V, l}^{\mathbf{H}_U}\right) = \frac{N_{x_V,l}}{\dbinom{|x_V|}{l}\dbinom{n/2-|x_V}{k_U-d-l}}
\end{equation}
Avec $N_{x_V,l}$ le nombre de mauvais sous-ensembles de $\llbracket1,n/A\rrbracket$ de taille $k_U-d$ pour $\mathbf{H}_U$.
\end{proof}


\begin{proof}[Preuve de la proposition \ref{dim_hull_UV}]
La dimension d'un $hull$ étant invariante par permutation nous allons ici montrer que nous avons $dim(hull(U,U+V)) = k_U - k_V$ avec probabilité $1-\mathcal{O}(2^{k_U-k_V})$.
Par définition du $hull$, nous avons :
\begin{equation*}
\begin{split}
hull(U,U+V) &= (U,U+V) \cap (U,U+V)^{\bot } \\
&= (U,U+V) \cap (V^{\bot}+U^{\bot}, V^{\bot}) \\
\end{split}
\end{equation*} 
Ainsi $\forall u\in U$ et $\forall v\in V$ tels que $(u,u+v)\in hull(U,U+V)$, il existe $u_t\in U^{\bot}$ et $v_t\in V^{\bot}$ tels que

\begin{equation*}
\left\{
\begin{aligned}
&u = v_t + u_t\\
&u + v = v_t\\
\end{aligned}
\right.
\iff
\left\{
\begin{aligned}
&v = u_t\\
&u + v = v_t\\
\end{aligned}
\right.
\end{equation*}
Donc $v\in V\cap U^{\bot}$.
De plus, nous avons $dim(V) + dim(U^{\bot}) = \frac{n}{2} +k_V - k_U < \frac{n}{2}$
SUITE À ÉCRIRE
\end{proof}

\bibliographystyle{plain}
\bibliography{bibliography}


\end{document}